# Twitter-Sentiment-Analysis-on-arms-regulation-in-US

In this project, we analyze twitter data over a period of three years to determine the trend in public opinion on existing gun laws in the United States in the context of various incidents of mass shootings that have occurred during the time frame. A raw dataset, consisting of thousands of tweets, is mined/processed to construct a database of tweets that contain public opinion on gun laws. The database is subjected to a machine learning algorithm that classifies the pro/anti gun sentiments of the general public. The results of the evaluation are demonstrated using data visualization frameworks that compare the number of pro and anti gun control sentiments and the impact of successive episodes of mass shootings on the above number. The visualization also depicts the impact of the location of a particular incident of mass shooting in relation to the location of the tweet on the opinion of gun control

* Data Preprocessing (TwitterDataPreprocessing.ipynb)

This file contains the logic to preprocess the raw twitter text that has been manually labelled.
The input file to be used here is similar to the attached sample file ‘elapso_labelled.csv’. It contains the following attribute columns -
‘date’, ‘retweets’, ‘favourites’, ‘label’, ‘text’.
The text column is subjected to various pre-processing techniques like stop-word removal, punctuation removal and tokenisation.
The tokenised text is stored as a new column in the file called as ‘clean_text’. 
The results of preprocessing are stored in a new csv file similar to the attached sample called ‘elpaso_tokenised.csv’. This file is later used to train the Machine Learning models along with the Word2Vec model.
The Word2Vec model is generated by creating a vector representation (of 200 dimensions) for each token in the clean_text column of the preprocessed twitter data.

* Machine Learning

(DBMSProject_MLmodels.ipynb)

Pandas library is used to read the preprocessed file generated in the first stage.
Bag of Words (BoW) and Term Frequency and Inverse Document Frequency (TF-IDF) models  are applied on the clean_text. 
The resulting embeddings are applied to different machine learning classifiers.

(DBMSProject_RNN.ipynb)
The trained tokenized dataset is transformed into the feature vectors suitable for LSTM.
The dataset is then split into train and test set for training the LSTM model.
The feature vectors are also derived for the unlabelled data.
The trained model is then used to predict the sentiment on the unseen dataset.

* Data Visualization (DBMSProject_Visualisation.ipynb)

The output of the RNN classifier is obtained and each tweet is given a label. 

For loading the webpage, run a simple http server on your system. D3.js loads data to the webpage through the server.

python -m http.server will allow you to run a simple http server

The jupyter notebook file, DBMSProject_Visualization.ipynb, consists of the code for bar graphs and pie charts. The html file includes the code for line graphs(D3.js) and CSS.

The four CSV files(one for each incident) are written in specific format for visualising them as line graphs. 



