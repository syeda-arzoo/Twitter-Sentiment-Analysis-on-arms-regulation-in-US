# Twitter-Sentiment-Analysis-on-arms-regulation-in-US


* Data Preprocessing (DBMSProject_Preprocessing.ipynb)

This file contains the logic to preprocess the raw twitter text that has been manually labelled.
The input file to be used here is similar to the attached sample ‘elapso_labelled.csv’. It contains the following attribute columns -
‘date’, ‘retweets’, ‘favourites’, ‘label’, ‘text’.
The text column is subjected to various pre-processing techniques like stop-word removal, punctuation removal and tokenisation.
The tokenised text is stored as a new column in the file called as ‘clean_text’. 
The results of preprocessing are stored in a new csv file similar to the attached sample called ‘elpaso_tokenised.csv’. This file is later used to train the Machine Learning models along with the Word2Vec model.
The Word2Vec model is generated by creating a vector representation (of 200 dimensions) for each token in the clean_text column of the preprocessed twitter data.

* Machine Learning

(DBMSProject_MLmodels.ipynb)
first we have to import panda then read the file
then execute the cell with boW features that works on clean_text gathered in the previous stage to analyse the features
then execute the TF-idf and the corresponding two cells following that to do the same for TF-IDF
Then for every classifier there is a cell with a comment mentioning the classifier

(DBMSProject_RNN.ipynb)
read the dataset using panda
then execute two following cell to clean the twitter text
execute each cell in its order until the next read_csv code
change the file name to the file of choice for unlabelled data 
then execute the same procedure on the unlabelled data
Then go to the word2vec cell where the tweets from both the labelled and unlabelled datasets are taken in order to train the word2vec model
Then transform the training tokenized dataset into the feature vector suitable for LSTM
Then perform the split on the dataset
Then execute the cell with LSTM model and the corresponding models to train and test LSTM 
Then transform the tokenised dataset of unlabelled data into a feature vector
Then use the model to predict the outcome 
execute the corresponding cells to save the output into a csv file

* Data Visualization (DBMSProject_Visualisation.ipynb)

The output of the RNN classifier is obtained and each tweet is given a label. After that, the tweets from every single day for each incident are obtained using python (code in jupyter notebook file). These results are stored in an excel file(results). The data in the four csv files is obtained from the excel file. 

For loading the webpage, run a simple http server on your system. D3.js loads data to the webpage through the server.

python -m http.server will allow you to run a simple http server

The jupyter notebook file, DBMSProject_Visualization.ipynb, consists of the code for bar graphs and pie charts. The html file includes the code for line graphs(D3.js) and CSS.

The four CSV files(one for each incident) are written in specific format for visualising them as line graphs. 



